{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j76d7aJfact6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install essential packages (if not already)\n",
        "!pip install -q mlflow imbalanced-learn optuna lightgbm boto3 awscli\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irA8vbR5T8z5",
        "outputId": "7b923382-e53c-4e00-8f45-6d9a752ad7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_tracking_uri('http://ec2-3-25-95-124.ap-southeast-2.compute.amazonaws.com:5000/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP0GP59f9G0s",
        "outputId": "21df5bf3-8a28-474a-b605-d176136e963e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://yt-mlflow-bkt/380195777977080659', creation_time=1751793285956, experiment_id='380195777977080659', last_update_time=1751793285956, lifecycle_stage='active', name='RF baseline model', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AKIATVPX5JRDSIFTBDVN\n",
        "# cjQ4CGFcF6KDlpIF2IXAiFA2P/Wim6zOq/uPWgqD\n",
        "# eu-north-1"
      ],
      "metadata": {
        "id": "r3ETiHggCJvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf6B9hdPCj8l",
        "outputId": "31a8c542-5f16-4ff5-efb4-f24a7dfc52d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWS Access Key ID [None]: AKIATVPX5JRDSIFTBDVN\n",
            "AWS Secret Access Key [None]: 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\n",
            "Default region name [None]: ap-southeast-2\n",
            "Default output format [None]: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HImqSTpkewsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Experiment 5: Detailed Hyperparameter Tuning on the Best Model derived from Experiment 4: LightGBM**\n"
      ],
      "metadata": {
        "id": "uKRFXcuIIGq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('preprocessed_data.csv')\n",
        "data['category'] = data['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "X = data['clean_comment']\n",
        "y = data['category']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Set MLflow experiment\n",
        "mlflow.set_experiment(\"exp5: detailed tuning best model (LightGBM)\")\n",
        "\n",
        "# TFIDF Vectorizer (1,3) grams, max 1000 features\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# SMOTE resampling\n",
        "sampler = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Optuna objective function for LightGBM\n",
        "def lgbm_objective(trial):\n",
        "    with mlflow.start_run(run_name=\"LightGBM_DetailedTuning\"):\n",
        "        mlflow.set_tag(\"experiment_type\", \"Detailed Tuning\")\n",
        "        mlflow.log_param(\"model\", \"LightGBM\")\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TFIDF\")\n",
        "        mlflow.log_param(\"max_features\", 1000)\n",
        "\n",
        "        # Detailed hyperparameter tuning space\n",
        "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 800)\n",
        "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True)\n",
        "        max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n",
        "        num_leaves = trial.suggest_int(\"num_leaves\", 20, 150)\n",
        "        min_child_samples = trial.suggest_int(\"min_child_samples\", 5, 100)\n",
        "        subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
        "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
        "        reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-3, 5.0, log=True) # L1 regularization\n",
        "        reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-3, 5.0, log=True) # L2 regularization\n",
        "\n",
        "        mlflow.log_params({\n",
        "            \"n_estimators\": n_estimators,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"num_leaves\": num_leaves,\n",
        "            \"max_depth\": max_depth,\n",
        "            \"min_child_samples\": min_child_samples,\n",
        "            \"subsample\": subsample,\n",
        "            \"colsample_bytree\": colsample_bytree,\n",
        "            \"reg_alpha\": reg_alpha,\n",
        "            \"reg_lambda\": reg_lambda\n",
        "        })\n",
        "\n",
        "        model = LGBMClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            num_leaves=num_leaves,\n",
        "            max_depth=max_depth,\n",
        "            min_child_samples=min_child_samples,\n",
        "            subsample=subsample,\n",
        "            colsample_bytree=colsample_bytree,\n",
        "            reg_alpha=reg_alpha,\n",
        "            reg_lambda=reg_lambda,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "\n",
        "        # conf_mat = confusion_matrix(y_test, y_pred)\n",
        "        # plt.figure(figsize=(8,6))\n",
        "        # sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
        "        # plt.title('Confusion Matrix: LightGBM Detailed Tuning')\n",
        "        # plt.savefig('conf_matrix_lgbm_detailed.png')\n",
        "        # mlflow.log_artifact('conf_matrix_lgbm_detailed.png')\n",
        "\n",
        "        mlflow.sklearn.log_model(model, \"lgbm_model\")\n",
        "\n",
        "        return acc\n",
        "\n",
        "# Run Optuna study for 100 detailed trials\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(lgbm_objective, n_trials=100)\n",
        "\n",
        "# Print best accuracy found\n",
        "print(f\"[LightGBM Detailed Tuning] Best Accuracy: {study.best_value:.4f}\")\n",
        "\n",
        "optuna.visualization.plot_optimization_history(study).show()\n",
        "optuna.visualization.plot_param_importances(study).show()\n"
      ],
      "metadata": {
        "id": "xV0PlPZdIQuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}